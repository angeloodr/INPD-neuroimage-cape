{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this cell separates the subjects and session of the frame displacement data\n",
    "abspath = os.path.abspath('__file__')\n",
    "dname = os.path.dirname(os.path.dirname(abspath))\n",
    "os.environ[\"ROOTDIR\"] = dname  # seth path\n",
    "rootdir = os.environ[\"ROOTDIR\"]\n",
    "\n",
    "metadata_path = os.path.join(rootdir, 'metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the subjects in the first wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(metadata_path,'sub_list_fd.csv'))\n",
    "## solitting the file name to sub ses func and \n",
    "sub_ses_df = data['file_name'].str.split('/', expand=True).drop([0,1,2,3,4,5,8,9],axis=1)\n",
    "## remove the file name of the actual data remaining the fd checking axis =1 means collunm\n",
    "fd_df = data.drop(['file_name'],axis=1)\n",
    "#concatenating the final data\n",
    "fd_data = pd.concat([sub_ses_df,fd_df],axis=1)\n",
    "fd_data = fd_data.rename(columns={6:'sub_id' , 7:'session'})\n",
    "fd_data.drop(fd_data[fd_data.session == 'ses-3'].index, inplace=True)\n",
    "fd_data.drop(fd_data[fd_data.session == 'ses-2'].index, inplace=True)\n",
    "fd_data = fd_data.sort_values(\"sub_id\") \n",
    "\n",
    "###### IMPORTANT: here false is optimal in both conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>session</th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-00003</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-00008</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-00015</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-00016</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sub-00019</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>sub-02496</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>sub-02502</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>sub-02507</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>sub-02509</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>sub-02510</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sub_id session    V1\n",
       "0     sub-00003   ses-1  True\n",
       "2     sub-00008   ses-1  True\n",
       "3     sub-00015   ses-1  True\n",
       "4     sub-00016   ses-1  True\n",
       "7     sub-00019   ses-1  True\n",
       "...         ...     ...   ...\n",
       "1514  sub-02496   ses-1  True\n",
       "1519  sub-02502   ses-1  True\n",
       "1522  sub-02507   ses-1  True\n",
       "1523  sub-02509   ses-1  True\n",
       "1525  sub-02510   ses-1  True\n",
       "\n",
       "[668 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READING THE DATA\n",
    "confund_data = pd.read_csv(os.path.join(metadata_path, 'checaCONFOUNDS.txt'), sep= \" \")\n",
    "sub_ids = pd.read_csv(os.path.join(metadata_path, 'subjects.txt'),sep=' ')\n",
    "#remove the unnecessary file names and indexes\n",
    "sub_ids = sub_ids['FILE_NAME'].str.split('/', expand=True).drop([2,3],axis=1)\n",
    "confund_data = confund_data.drop(['index','V2'], axis=1)\n",
    "\n",
    "conf_sub_data = pd.concat([sub_ids, confund_data['V1']==181], axis=1)\n",
    "conf_sub_data = conf_sub_data.rename({0 : 'sub_id', 1:'session'}, axis=1)\n",
    "#dopping other sessions / wave\n",
    "conf_sub_data.drop(conf_sub_data[conf_sub_data.session == 'ses-3'].index, inplace=True)\n",
    "conf_sub_data.drop(conf_sub_data[conf_sub_data.session == 'ses-2'].index, inplace=True)\n",
    "conf_sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_mean_value</th>\n",
       "      <th>fd_count_high</th>\n",
       "      <th>fd_count_high_value</th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-00003</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072094</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-00008</td>\n",
       "      <td>True</td>\n",
       "      <td>0.311252</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-00015</td>\n",
       "      <td>False</td>\n",
       "      <td>0.118437</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-00016</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587256</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-00019</td>\n",
       "      <td>False</td>\n",
       "      <td>0.129256</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>sub-02496</td>\n",
       "      <td>False</td>\n",
       "      <td>0.131778</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>sub-02502</td>\n",
       "      <td>False</td>\n",
       "      <td>0.157067</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>sub-02507</td>\n",
       "      <td>False</td>\n",
       "      <td>0.096652</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>sub-02509</td>\n",
       "      <td>False</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>sub-02510</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174041</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sub_id  fd_mean  fd_mean_value  fd_count_high  fd_count_high_value  \\\n",
       "0    sub-00003    False       0.072094          False                    3   \n",
       "1    sub-00008     True       0.311252           True                   51   \n",
       "2    sub-00015    False       0.118437          False                    3   \n",
       "3    sub-00016     True       0.587256           True                  101   \n",
       "4    sub-00019    False       0.129256          False                   17   \n",
       "..         ...      ...            ...            ...                  ...   \n",
       "663  sub-02496    False       0.131778           True                   21   \n",
       "664  sub-02502    False       0.157067          False                   16   \n",
       "665  sub-02507    False       0.096652          False                    8   \n",
       "666  sub-02509    False       0.092963          False                    2   \n",
       "667  sub-02510    False       0.174041           True                   24   \n",
       "\n",
       "       V1  \n",
       "0    True  \n",
       "1    True  \n",
       "2    True  \n",
       "3    True  \n",
       "4    True  \n",
       "..    ...  \n",
       "663  True  \n",
       "664  True  \n",
       "665  True  \n",
       "666  True  \n",
       "667  True  \n",
       "\n",
       "[668 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.merge(fd_data, conf_sub_data, on=['sub_id','session'])\n",
    "df2 = df2.drop(['session'], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading sociodemografic and psicometric data and doing random sample imputation for the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2249 entries, 2 to 2509\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ident          2249 non-null   int64  \n",
      " 1   gender         2249 non-null   int64  \n",
      " 2   abepscore      2249 non-null   int64  \n",
      " 3   trauma_exp     2249 non-null   float64\n",
      " 4   age            2249 non-null   float64\n",
      " 5   DQ             2249 non-null   float64\n",
      " 6   subjectid      2249 non-null   int64  \n",
      " 7   cape_tot       2249 non-null   float64\n",
      " 8   cape_PA_score  2249 non-null   float64\n",
      " 9   cape_PI_score  2249 non-null   float64\n",
      " 10  cape_BE_score  2249 non-null   float64\n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 210.8 KB\n"
     ]
    }
   ],
   "source": [
    "#Reading the data\n",
    "socidemo_path = os.path.join(rootdir,'fMRI_INPD_sociodemographic')\n",
    "socio_psi = pd.read_excel(os.path.join(socidemo_path,'banco_angelo.xlsx'))\n",
    "\n",
    "dados_clinicos = socio_psi[['ident', 'gender', 'abepscore','trauma_exp', 'age', 'DQ','subjectid', 'cape_tot', 'cape_PA_score', 'cape_PI_score', 'cape_BE_score']]\n",
    "# dropping subjects that dont ha cape_tot value\n",
    "dados_clinicos = dados_clinicos[dados_clinicos['cape_tot'].notna()]\n",
    "# ramdom sample\n",
    "def random_sample_imputation(df):\n",
    "   \n",
    "    cols_with_missing_values = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "    for var in cols_with_missing_values:\n",
    "\n",
    "        # extract a random sample\n",
    "        random_sample_df = df[var].dropna().sample(df[var].isnull().sum(),\n",
    "                                                    random_state=0, replace=True)\n",
    "        # re-index the randomly extracted sample\n",
    "        random_sample_df.index = df[\n",
    "                df[var].isnull()].index\n",
    "\n",
    "        # replace the NA\n",
    "        df.loc[df[var].isnull(), var] = random_sample_df\n",
    "    \n",
    "    return df\n",
    "\n",
    "dados_clinicos = random_sample_imputation(dados_clinicos)\n",
    "dados_clinicos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in dados_clinicos['ident']:  \n",
    "    dados_clinicos['ident'] = dados_clinicos['ident'].replace(index, 'sub-{}'.format(str(index).zfill(5)))\n",
    "dados_clinicos = dados_clinicos.rename(columns={'ident':'sub_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging neuroimage masures to psicometric and sociodemo dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>abepscore</th>\n",
       "      <th>trauma_exp</th>\n",
       "      <th>age</th>\n",
       "      <th>DQ</th>\n",
       "      <th>subjectid</th>\n",
       "      <th>cape_tot</th>\n",
       "      <th>cape_PA_score</th>\n",
       "      <th>cape_PI_score</th>\n",
       "      <th>cape_BE_score</th>\n",
       "      <th>fd_mean</th>\n",
       "      <th>fd_mean_value</th>\n",
       "      <th>fd_count_high</th>\n",
       "      <th>fd_count_high_value</th>\n",
       "      <th>V1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-00003</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.361396</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072094</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-00008</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.569473</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10103</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.311252</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-00015</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.221766</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10134</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.118437</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-00016</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.619439</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587256</td>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-00019</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.049966</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10713</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.129256</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>sub-02496</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.038330</td>\n",
       "      <td>86.0</td>\n",
       "      <td>20294</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.131778</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>sub-02502</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.911020</td>\n",
       "      <td>88.0</td>\n",
       "      <td>21004</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.157067</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>sub-02507</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.440794</td>\n",
       "      <td>106.0</td>\n",
       "      <td>20046</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.096652</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>sub-02509</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.933607</td>\n",
       "      <td>109.0</td>\n",
       "      <td>20671</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>sub-02510</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.800821</td>\n",
       "      <td>91.0</td>\n",
       "      <td>20717</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174041</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>663 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sub_id  gender  abepscore  trauma_exp        age     DQ  subjectid  \\\n",
       "0    sub-00003       2         10         0.0   8.361396   94.0      10059   \n",
       "1    sub-00008       1         16         0.0  12.569473   76.0      10103   \n",
       "2    sub-00015       2         19         0.0  12.221766   85.0      10134   \n",
       "3    sub-00016       1         10         1.0  11.619439  100.0      10210   \n",
       "4    sub-00019       2         13         0.0  11.049966   75.0      10713   \n",
       "..         ...     ...        ...         ...        ...    ...        ...   \n",
       "661  sub-02496       1         17         0.0   8.038330   86.0      20294   \n",
       "662  sub-02502       1         23         1.0   9.911020   88.0      21004   \n",
       "663  sub-02507       1         19         0.0   8.440794  106.0      20046   \n",
       "664  sub-02509       1         14         0.0   8.933607  109.0      20671   \n",
       "665  sub-02510       2         17         0.0   6.800821   91.0      20717   \n",
       "\n",
       "     cape_tot  cape_PA_score  cape_PI_score  cape_BE_score  fd_mean  \\\n",
       "0         1.0            0.0            1.0            0.0    False   \n",
       "1         7.0            0.0            2.0            2.0     True   \n",
       "2         5.0            0.0            4.0            0.0    False   \n",
       "3         1.0            0.0            1.0            0.0     True   \n",
       "4         4.0            0.0            2.0            0.0    False   \n",
       "..        ...            ...            ...            ...      ...   \n",
       "661      12.0            2.0            5.0            3.0    False   \n",
       "662       6.0            0.0            2.0            0.0    False   \n",
       "663       4.0            0.0            1.0            1.0    False   \n",
       "664      14.0            0.0            3.0            4.0    False   \n",
       "665       8.0            0.0            4.0            3.0    False   \n",
       "\n",
       "     fd_mean_value  fd_count_high  fd_count_high_value    V1  \n",
       "0         0.072094          False                    3  True  \n",
       "1         0.311252           True                   51  True  \n",
       "2         0.118437          False                    3  True  \n",
       "3         0.587256           True                  101  True  \n",
       "4         0.129256          False                   17  True  \n",
       "..             ...            ...                  ...   ...  \n",
       "661       0.131778           True                   21  True  \n",
       "662       0.157067          False                   16  True  \n",
       "663       0.096652          False                    8  True  \n",
       "664       0.092963          False                    2  True  \n",
       "665       0.174041           True                   24  True  \n",
       "\n",
       "[663 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(dados_clinicos, df2, on=['sub_id'])\n",
    "df_final = df_final.query('V1 == True')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing subjects due to excluion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with manual inspection \n",
    "# Open the file and read the content\n",
    "with open(os.path.join(metadata_path,'subid_imagem-ruim.txt'), 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split based on commas (or any other delimiter)\n",
    "variables = content.split(' ')  # Adjust the delimiter as needed\n",
    "\n",
    "# Remover entradas vazias, caso existam\n",
    "variables = [s for s in variables if s]\n",
    "\n",
    "# Criar uma lista de listas fazendo o split\n",
    "split_data = [s.split('_') for s in variables]\n",
    "\n",
    "# Criar o DataFrame com base nos resultados do split\n",
    "manIsnpec = pd.DataFrame(split_data, columns=['sub_id', 'session', 'func', 'sub_id_2', 'session_2', 'task', 'run', 'space', 'resolution', 'description', 'new'])\n",
    "\n",
    "# Organizing the dataset for only selecting impartant features, such as w0 images aka ses-1\n",
    "manIsnpec = manIsnpec.drop(['func', 'sub_id_2', 'session_2', 'task', 'run', 'space', 'resolution', 'description', 'new'], axis=1)\n",
    "manIsnpec = manIsnpec.query('session == \"ses-1\"')\n",
    "df_final = pd.merge(df_final, manIsnpec, on='sub_id', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "663\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "# dropping the subjects that have to be removed by qualy control of images\n",
    "threshold_fdmean, threshold_fdcount, threshold_DQ = 0.3, 30, 70\n",
    "\n",
    "df_final_fdmean = df_final.query(f'fd_mean<={threshold_fdmean}')\n",
    "print(df_final_fdmean.shape[0])\n",
    "df_final_fdhigh = df_final.query(f'fd_count_high <={threshold_fdcount}')\n",
    "print(df_final_fdhigh.shape[0])\n",
    "df_final_dq = df_final.query(f'DQ >= {threshold_DQ}')\n",
    "print(df_final_dq.shape[0])\n",
    "\n",
    "df_final_final = df_final.query(f'fd_mean<={threshold_fdmean} and fd_count_high <={threshold_fdcount} and DQ >= {threshold_DQ}')\n",
    "df_final_final = df_final_final.drop(['fd_mean', 'fd_mean_value', 'fd_count_high', 'V1', 'DQ', 'trauma_exp'], axis=1)\n",
    "\n",
    "# identifying the site of colection\n",
    "df_final_final['subjectid'] = np.floor(df_final['subjectid']/10000)\n",
    "df_final_final.rename(columns={'subjectid':'colection_site'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing the databases after exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final_maninspect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m titles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final_fdhigh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final_fdmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final_maninspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Iterar sobre os DataFrames e adicionar os grÃ¡ficos\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idf, data_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([df_final, df_final_fdhigh, df_final_fdmean, \u001b[43mdf_final_maninspect\u001b[49m]):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m indexx, var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabepscore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrauma_exp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDQ\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubjectid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcape_tot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcape_PA_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcape_PI_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcape_BE_score\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     13\u001b[0m         \n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# Subplot: 4 linhas, 10 colunas\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39midf \u001b[38;5;241m+\u001b[39m indexx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_final_maninspect' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir a figura\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# Lista de tÃ­tulos para cada DataFrame\n",
    "titles = ['df_final', 'df_final_fdhigh', 'df_final_fdmean', 'df_final_maninspect']\n",
    "\n",
    "# Iterar sobre os DataFrames e adicionar os grÃ¡ficos\n",
    "for idf, data_frame in enumerate([df_final, df_final_fdhigh, df_final_fdmean, df_final_maninspect]):\n",
    "    for indexx, var in enumerate(['gender', 'abepscore', 'trauma_exp', 'age', 'DQ',\n",
    "                                  'subjectid', 'cape_tot', 'cape_PA_score', 'cape_PI_score', 'cape_BE_score']):\n",
    "        \n",
    "        # Subplot: 4 linhas, 10 colunas\n",
    "        plt.subplot(4, 10, 10*idf + indexx+1)\n",
    "        \n",
    "        # Adicionar o histograma para a variÃ¡vel\n",
    "        plt.title(var, fontsize=8)  # TÃ­tulo de cada grÃ¡fico\n",
    "        plt.hist(data_frame[var])\n",
    "        \n",
    "        # Remover o eixo vertical e os valores do grÃ¡fico\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)  # Esconde o eixo Y\n",
    "        plt.gca().spines['left'].set_visible(False)    # Remove a linha do eixo Y\n",
    "        plt.gca().spines['right'].set_visible(False)   # Remove a linha do eixo Y\n",
    "        plt.gca().spines['top'].set_visible(False)     # Remove a linha do eixo Y\n",
    "        plt.gca().spines['bottom'].set_visible(False)  # Remove a linha do eixo Y\n",
    "    \n",
    "    # Adicionar tÃ­tulo para cada linha (DataFrame) com suptitle\n",
    "    plt.suptitle(titles[idf], fontsize=14, weight='bold', y=1-(idf * 0.25))  # Ajustar a posiÃ§Ã£o com 'y'\n",
    "\n",
    "# Ajustar o layout para evitar sobreposiÃ§Ã£o\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])  # Deixar espaÃ§o no topo para os tÃ­tulos\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final.to_excel(os.path.join(metadata_path,'variaveis_analise_conf.xlsx'))\n",
    "# df_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = df_final[['gender', 'abepscore']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_fmriINPD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
